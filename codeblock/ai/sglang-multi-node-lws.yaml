apiVersion: leaderworkerset.x-k8s.io/v1
kind: LeaderWorkerSet
metadata:
  name: sglang
spec:
  replicas: 1
  leaderWorkerTemplate:
    size: 2
    restartPolicy: RecreateGroupOnPodRestart
    leaderTemplate:
      metadata:
        labels:
          role: leader
      spec:
        containers:
        - name: sglang-leader
          image: lmsysorg/sglang:latest
          command:
          - bash
          - -c
          - |
            set -x
            exec python3 -m sglang.launch_server \
              --model-path /data/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B \
              --nnodes $LWS_GROUP_SIZE \
              --tp 8 \
              --node-rank 0 \
              --dist-init-addr $(LWS_LEADER_ADDRESS):5000 \
              --trust-remote-code \
              --host 0.0.0.0 \
              --port 30000
          resources:
            limits:
              nvidia.com/gpu: "4"
          ports:
          - containerPort: 30000
          volumeMounts:
          - mountPath: /dev/shm
            name: dshm
          - mountPath: /data
            name: data
        volumes:
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: 40Gi
        - name: data
          persistentVolumeClaim:
            claimName: ai-model
    workerTemplate:
      spec:
        containers:
        - name: sglang-worker
          image: lmsysorg/sglang:latest
          env:
          - name: ORDINAL_NUMBER
            valueFrom:
              fieldRef:
                fieldPath: metadata.labels['apps.kubernetes.io/pod-index']
          command:
          - bash
          - -c
          - |
            set -x
            exec python3 -m sglang.launch_server \
              --model-path /data/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B \
              --nnodes $LWS_GROUP_SIZE \
              --tp 8 \
              --node-rank $ORDINAL_NUMBER \
              --dist-init-addr $(LWS_LEADER_ADDRESS):5000 \
              --trust-remote-code
          resources:
            limits:
              nvidia.com/gpu: "4"
          volumeMounts:
          - mountPath: /dev/shm
            name: dshm
          - mountPath: /data
            name: data
        volumes:
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: 40Gi
        - name: data
          persistentVolumeClaim:
            claimName: ai-model
