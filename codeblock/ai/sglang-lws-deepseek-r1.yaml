apiVersion: leaderworkerset.x-k8s.io/v1
kind: LeaderWorkerSet
metadata:
  name: deepseek-r1
spec:
  replicas: 1
  leaderWorkerTemplate:
    size: 4
    restartPolicy: RecreateGroupOnPodRestart
    leaderTemplate:
      metadata:
        labels:
          role: leader
      spec:
        terminationGracePeriodSeconds: 1
        containers:
        - name: leader
          image: lmsysorg/sglang:latest
          command:
          - bash
          - -c
          - |
            set -x
            exec python3 -m sglang.launch_server \
              --model-path /data/DeepSeek-R1 \
              --nnodes $LWS_GROUP_SIZE \
              --tp 4 \
              --node-rank 0 \
              --dist-init-addr $(LWS_LEADER_ADDRESS):5000 \
              --trust-remote-code \
              --host 0.0.0.0 \
              --port 30000
          resources:
            limits:
              nvidia.com/gpu: "4"
          ports:
          - containerPort: 30000
          volumeMounts:
          - mountPath: /dev/shm
            name: dshm
          - mountPath: /data
            name: data
        volumes:
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: 40Gi
        - name: data
          persistentVolumeClaim:
            claimName: ai-model-turbo
    workerTemplate:
      spec:
        terminationGracePeriodSeconds: 1
        containers:
        - name: worker
          image: lmsysorg/sglang:latest
          env:
          - name: ORDINAL_NUMBER
            valueFrom:
              fieldRef:
                fieldPath: metadata.labels['apps.kubernetes.io/pod-index']
          command:
          - bash
          - -c
          - |
            set -x
            exec python3 -m sglang.launch_server \
              --model-path /data/DeepSeek-R1 \
              --nnodes $LWS_GROUP_SIZE \
              --tp 4 \
              --node-rank $ORDINAL_NUMBER \
              --dist-init-addr $(LWS_LEADER_ADDRESS):5000 \
              --trust-remote-code
          resources:
            limits:
              nvidia.com/gpu: "4"
          volumeMounts:
          - mountPath: /dev/shm
            name: dshm
          - mountPath: /data
            name: data
        volumes:
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: 40Gi
        - name: data
          persistentVolumeClaim:
            claimName: ai-model
